# GitHub Models Configuration
# Get your token from: https://github.com/settings/tokens
GITHUB_API_KEY=your_github_token_here

# Preferred GitHub Model (available options)
GITHUB_MODEL=gpt-4o-mini
# GITHUB_MODEL=gpt-4o
# GITHUB_MODEL=deepseek-chat
# GITHUB_MODEL=deepseek/DeepSeek-V3-0324
# GITHUB_MODEL=Meta-Llama-3.1-8B-Instruct
# GITHUB_MODEL=Meta-Llama-3.1-70B-Instruct

# GitHub Models Endpoint
GITHUB_ENDPOINT=https://models.github.ai/inference

# LLM Provider Priority
DEFAULT_LLM_PROVIDER=github

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_key_here
OPENAI_MODEL=gpt-4o-mini

# Ollama Configuration (if using Ollama)
OLLAMA_MODEL=llama3.1:8b-instruct-q8_0
OLLAMA_BASE_URL=http://localhost:11434

# Flask Configuration
FLASK_SECRET_KEY=your-secret-key-here
ENV=development
